<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Simple Face Detection</title>

  <!-- Load TensorFlow.js and BlazeFace model -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.11.0"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/blazeface"></script>

  <style>
    body { text-align:center; 
        
    font-family:sans-serif; margin-top:30px; }

    canvas { 
        border:2px solid #4caf50;
         margin-top:10px; }
  </style>
</head>
<body>

  <h2>Face Detection App</h2>
  <input type="file" id="fileInput" accept="image/*"><br>
  <canvas id="canvas"></canvas>
 
  <script>
    let model;   // holds the loaded face-detection model

    // // Step 1: Load BlazeFace model when page opens
    // blazeface.load().then(m => {
    //   model = m;
    //   alert("âœ… Model Loaded â€” Ready to detect faces!");
    // });

//      // Step 1: Load the model
  blazeface.load().then(function(m) {
    model = m;
    alert("Model Loaded!");
  });

    // Step 2: When user uploads an image
    document.getElementById("fileInput").addEventListener("change", async (e) => {
      if (!model) return alert("Model not ready yet!");

      // Create <img> element to read file
      const img = new Image();
      img.src = URL.createObjectURL(e.target.files[0]);

      img.onload = async () => {
        const canvas = document.getElementById("canvas");
        const ctx = canvas.getContext("2d");
        canvas.width = img.width;
        canvas.height = img.height;
        ctx.drawImage(img, 0, 0);


//         The img.onload function runs after the image has fully loaded.
// Inside it, we get the canvas element, prepare a 2D drawing context, set the canvas size equal to the image size, and then draw the image on the canvas.
// This allows the face detection model to analyze the image/ pixels later.â€

        // Step 3: Detect faces
        const faces = await model.estimateFaces(canvas);
        if (faces.length === 0) {
          alert("No faces found!");
          return;
        }

        //model.estimateFaces(canvas)
// ðŸ‘‰ This tells the BlazeFace model to look at the image drawn on the canvas and find all the faces.
// It returns a list (array) of all faces it detects â€” each face has coordinates like top-left and bottom-right points.

// await
// ðŸ‘‰ Means â€œwait until the model finishes checking the image.â€
// (Because detection takes a little time.)

// faces.length === 0
// ðŸ‘‰ Checks if the model found zero faces.
// If yes, it shows an alert message â€” â€œNo faces found!â€ â€” and stops the function.



        // Step 4: Draw red rectangles around detected faces
        ctx.strokeStyle = "red";
        ctx.lineWidth = 2;
        faces.forEach((face, i) => {
          const [x1, y1] = face.topLeft;
          const [x2, y2] = face.bottomRight;
          const w = x2 - x1, h = y2 - y1;
          ctx.strokeRect(x1, y1, w, h);
          ctx.fillStyle = "red";
          ctx.font = "16px Arial";
          ctx.fillText(`Face ${i+1}`, x1, y1 - 5);
        });
      };
    });
  </script>

</body>
</html>
